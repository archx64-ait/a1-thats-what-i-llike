{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import datapath\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "#you have to put this file in some python/gensim directory; just run it and it will inform where to put....\n",
    "glove_file = datapath('glove.6B.100d.txt')\n",
    "model = KeyedVectors.load_word2vec_format(glove_file, binary=False, no_header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.spatial.distance import cosine\n",
    "import numpy as np\n",
    "\n",
    "def cos_sim(a, b):\n",
    "    return 1 - spatial.distance.cosine(\n",
    "        a, b\n",
    "    )  # distance = 1 - similarlity, because scipy only gives distance\n",
    "\n",
    "def find_closest_word(vec, embeddings, exclude_ids):\n",
    "    max_similarity = -float(\"inf\")\n",
    "    best_idx = -1\n",
    "\n",
    "    for idx, emb in enumerate(embeddings):\n",
    "        if idx in exclude_ids:\n",
    "            continue\n",
    "        similarity = cos_sim(vec, emb)\n",
    "        if similarity > max_similarity:\n",
    "            max_similarity = similarity\n",
    "            best_idx = idx\n",
    "\n",
    "    return best_idx\n",
    "\n",
    "def load_specific_categories(file_path, semantic_category, syntactic_category):\n",
    "    semantic = []\n",
    "    syntactic = []\n",
    "    current_group = None\n",
    "\n",
    "    with open(file_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            if line.startswith(\":\"):\n",
    "                if semantic_category in line.lower():\n",
    "                    current_group = semantic\n",
    "                elif syntactic_category in line.lower():\n",
    "                    current_group = syntactic\n",
    "                else:\n",
    "                    current_group = None\n",
    "            elif current_group is not None:\n",
    "                words = line.strip().split()\n",
    "                if len(words) == 4:\n",
    "                    current_group.append(words)\n",
    "\n",
    "    return semantic, syntactic\n",
    "\n",
    "def evaluate_word_analogies_with_custom_functions(model, file_path):\n",
    "    semantic_analogies, syntactic_analogies = load_specific_categories(\n",
    "        file_path, 'semantic', 'syntactic'\n",
    "    )\n",
    "\n",
    "    word_to_idx = model.key_to_index\n",
    "    embeddings = model.vectors  \n",
    "\n",
    "    syntactic_accuracy = evaluate_analogies(syntactic_analogies, word_to_idx, embeddings)\n",
    "    print(f\"Syntactic Accuracy: {syntactic_accuracy}\")\n",
    "\n",
    "    semantic_accuracy = evaluate_analogies(semantic_analogies, word_to_idx, embeddings)\n",
    "    print(f\"Semantic Accuracy: {semantic_accuracy}\")\n",
    "\n",
    "\n",
    "def load_analogies(file_path):\n",
    "    analogies = []\n",
    "    current_category = None\n",
    "\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line.startswith(\":\"):\n",
    "                current_category = line[1:].strip()\n",
    "            elif line and not line.startswith(\"//\"):\n",
    "                words = line.split()\n",
    "                if len(words) == 4:\n",
    "                    analogies.append(tuple(words))\n",
    "    \n",
    "    return analogies\n",
    "\n",
    "def evaluate_analogies(analogy_data, word_to_idx, embeddings):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for word1, word2, word3, word4 in analogy_data:\n",
    "        if all(word in word_to_idx for word in [word1, word2, word3, word4]):\n",
    "            idx1 = word_to_idx[word1]\n",
    "            idx2 = word_to_idx[word2]\n",
    "            idx3 = word_to_idx[word3]\n",
    "            idx4 = word_to_idx[word4]\n",
    "\n",
    "            vec = embeddings[idx2] - embeddings[idx1] + embeddings[idx3]\n",
    "\n",
    "            # get the most similar word to the analogy vector\n",
    "            predicted_idx = find_closest_word(vec, embeddings, {idx1, idx2, idx3})\n",
    "            \n",
    "            # ensure the predicted word matches the fourth word in the analogy\n",
    "            if predicted_idx == idx4:\n",
    "                correct += 1\n",
    "\n",
    "            total += 1\n",
    "        else:\n",
    "            print(f\"Skipping analogy {word1}, {word2}, {word3}, {word4} due to missing words\")\n",
    "\n",
    "    # Return accuracy if total > 0, otherwise 0\n",
    "    return correct / total if total > 0 else 0\n",
    "\n",
    "\n",
    "def load_wordsim353(file_path):\n",
    "    word_pairs = []\n",
    "    human_scores = []\n",
    "\n",
    "    with open(file_path, \"r\") as f:\n",
    "        next(f)\n",
    "        for line in f:\n",
    "            word1, word2, score = line.strip().split()\n",
    "            word_pairs.append((word1, word2))\n",
    "            human_scores.append(float(score))\n",
    "\n",
    "    return word_pairs, human_scores\n",
    "\n",
    "\n",
    "def calculate_model_similarity(word_pairs, model, word_to_idx):\n",
    "    model_scores = []\n",
    "    embeddings = model.vectors  # access embeddings directly from the KeyedVectors object\n",
    "\n",
    "    for word1, word2 in word_pairs:\n",
    "        if word1 in word_to_idx and word2 in word_to_idx:\n",
    "            idx1 = word_to_idx[word1]\n",
    "            idx2 = word_to_idx[word2]\n",
    "            # get cosine similarity (dot product is equivalent to 1 - cosine distance)\n",
    "            similarity = 1 - cosine(embeddings[idx1], embeddings[idx2])\n",
    "            model_scores.append(similarity)\n",
    "        else:\n",
    "            model_scores.append(None)  # handle OOV (out-of-vocabulary) words\n",
    "    return model_scores\n",
    "\n",
    "def compute_spearman_correlation(human_scores, model_scores):\n",
    "    valid_scores = [(h, m) for h, m in zip(human_scores, model_scores) if m is not None]\n",
    "    filtered_human_scores, filtered_model_scores = zip(*valid_scores)\n",
    "\n",
    "    correlation, _ = spearmanr(filtered_human_scores, filtered_model_scores)\n",
    "    return correlation\n",
    "\n",
    "def compute_mse(human_scores, model_scores):\n",
    "    #remove null values from model_scores\n",
    "    valid_scores = [(h, m) for h, m in zip(human_scores, model_scores) if m is not None]\n",
    "    filtered_human_scores, filtered_model_scores = zip(*valid_scores)\n",
    "\n",
    "    mse = np.mean((np.array(filtered_model_scores) - np.array(filtered_human_scores)) ** 2)\n",
    "    return mse\n",
    "\n",
    "def compute_average_human_score(human_scores):\n",
    "    return sum(human_scores) / len(human_scores)\n",
    "\n",
    "def load_wordsim353(file_path):\n",
    "    word_pairs = []\n",
    "    human_scores = []\n",
    "\n",
    "    with open(file_path, \"r\") as f:\n",
    "        next(f)\n",
    "        for line in f:\n",
    "            word1, word2, score = line.strip().split()\n",
    "            word_pairs.append((word1, word2))\n",
    "            human_scores.append(float(score))\n",
    "\n",
    "    return word_pairs, human_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_analogies, syntactic_analogies = load_specific_categories(\n",
    "        'word-analogies.txt', 'semantic', 'syntactic'\n",
    "    )\n",
    "\n",
    "word_to_idx = model.key_to_index\n",
    "embeddings = model.vectors  \n",
    "\n",
    "syntactic_accuracy = evaluate_analogies(syntactic_analogies, word_to_idx, embeddings)\n",
    "# print(f\"Syntactic Accuracy: {syntactic_accuracy}\")\n",
    "\n",
    "semantic_accuracy = evaluate_analogies(semantic_analogies, word_to_idx, embeddings)\n",
    "# print(f\"Semantic Accuracy: {semantic_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syntactic_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semantic_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_pairs, human_scores = load_wordsim353('wordsim353/wordsim_similarity_goldstandard.txt') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scores = calculate_model_similarity(word_pairs, model, model.key_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove null values from both human_scores and model_scores\n",
    "valid_scores = [(h, m) for h, m in zip(human_scores, model_scores) if m is not None]\n",
    "filtered_human_scores, filtered_model_scores = zip(*valid_scores) if valid_scores else ([], [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.76131250197865"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = compute_mse(human_scores, model_scores)\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spearman correlation between model similarity and human judgment: 0.6008007400861295\n"
     ]
    }
   ],
   "source": [
    "if filtered_human_scores and filtered_model_scores:\n",
    "    correlation, _ = spearmanr(filtered_human_scores, filtered_model_scores)\n",
    "    print(f\"spearman correlation between model similarity and human judgment: {correlation}\")\n",
    "else:\n",
    "    print(\"no valid word pairs to compute spearman correlation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model is highly correlated to human judgement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get top 10 similar words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_top_k_dot_product(query_word, model, k=10):\n",
    "    if query_word not in model.key_to_index:\n",
    "        raise ValueError(f\"Word '{query_word}' not in vocabulary.\")\n",
    "    \n",
    "    query_vector = model[query_word]  \n",
    "    \n",
    "    # all word vectors (corpus vectors)\n",
    "    corpus_vectors = model.vectors\n",
    "    \n",
    "    #  dot product between the query vector and all word vectors in the corpus\n",
    "    dot_products = np.dot(corpus_vectors, query_vector)\n",
    "    \n",
    "    # top k indices that correspond to the highest dot product values\n",
    "    top_k_indices = np.argsort(dot_products)[-k:][::-1]  # Sorting in descending order\n",
    "    \n",
    "    # top k words and their corresponding similarity scores\n",
    "    top_k_words = [model.index_to_key[i] for i in top_k_indices]\n",
    "    top_k_scores = dot_products[top_k_indices]\n",
    "    \n",
    "    return top_k_words, top_k_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "king\n",
      "emperor\n",
      "prince\n",
      "queen\n",
      "son\n",
      "ii\n",
      "throne\n",
      "father\n",
      "lord\n",
      "kingdom\n"
     ]
    }
   ],
   "source": [
    "query_word = \"king\"\n",
    "top_k_words, top_k_scores = compute_top_k_dot_product(query_word, model, k=10)\n",
    "\n",
    "for word in top_k_words:\n",
    "    print(word)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gensim-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
