{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import datapath\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "#you have to put this file in some python/gensim directory; just run it and it will inform where to put....\n",
    "glove_file = datapath('glove.6B.100d.txt')\n",
    "model = KeyedVectors.load_word2vec_format(glove_file, binary=False, no_header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to your word-analogies.txt file\n",
    "analogies_file = 'word-analogies.txt'\n",
    "\n",
    "# Evaluate the model on the analogies\n",
    "results = model.evaluate_word_analogies(analogies_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_sections = ['capital-common-countries']\n",
    "syntactic_sections = ['gram7-past-tense']\n",
    "semantic_correct = 0\n",
    "semantic_total = 0\n",
    "syntactic_correct = 0\n",
    "syntactic_total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for section in results[1]:  # results[1] contains per-section details\n",
    "    if section['section'] in semantic_sections:\n",
    "        semantic_correct += len(section['correct'])  \n",
    "        semantic_total += len(section['correct']) + len(section['incorrect'])  # total examples\n",
    "    elif section['section'] in syntactic_sections:\n",
    "        syntactic_correct += len(section['correct']) \n",
    "        syntactic_total += len(section['correct']) + len(section['incorrect'])  # total examples\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_accuracy = semantic_correct / semantic_total if semantic_total > 0 else 0\n",
    "syntactic_accuracy = syntactic_correct / syntactic_total if syntactic_total > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "semantic Accuracy: 93.87%\n",
      "syntactic Accuracy: 55.45%\n"
     ]
    }
   ],
   "source": [
    "print(f\"semantic Accuracy: {semantic_accuracy:.2%}\")\n",
    "print(f\"syntactic Accuracy: {syntactic_accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_file = 'wordsim353/wordsim_similarity_goldstandard.txt'\n",
    "model_similarities = []\n",
    "human_similarities = []\n",
    "\n",
    "with open(similarity_file, 'r') as file:\n",
    "    for line in file:\n",
    "        word1, word2, human_score = line.strip().split('\\t')\n",
    "        human_score = float(human_score)\n",
    "        \n",
    "        # make sure that words are in the vocabulary\n",
    "        if word1 in model and word2 in model:\n",
    "            # get dot product (cosine similarity since vectors are normalized in KeyedVectors)\n",
    "            model_score = model.similarity(word1, word2)\n",
    "            model_similarities.append(model_score)\n",
    "            human_similarities.append(human_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "from sklearn.metrics import mean_squared_error\n",
    "correlation, _ = spearmanr(model_similarities, human_similarities)\n",
    "mse = mean_squared_error(human_similarities, model_similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spearman's correlation: 0.6019\n",
      "mean Squared Error (MSE): 27.8562\n"
     ]
    }
   ],
   "source": [
    "print(f\"spearman's correlation: {correlation:.4f}\")\n",
    "print(f\"mean Squared Error (MSE): {mse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GloVe(Gensim) model has high correlation with human judgement"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gensim-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
